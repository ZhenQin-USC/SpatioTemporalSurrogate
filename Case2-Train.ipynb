{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1839f5ad-8092-4272-82cf-e2d3fced1978",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6a5e2e-11c4-4299-977b-2f7175d06c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directories\n",
    "path_to_data = '/project2/jafarpou_227/Storage_Folder/Zhen/Data/CO2_Dataset/grid2D_512_128_gaussian' # path to your data\n",
    "path_to_project = '/scratch1/zhenq/2.SpatioTemporalSurrogate' # path to your codebase\n",
    "path_to_model = '/scratch1/zhenq/2.SpatioTemporalSurrogate/checkpoint_case2D/runet_base_RMSE' # path to checkpoint\n",
    "path_to_config = 'config/case2_2D_runet.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18a1a1e-f6ad-4030-9687-b19c1b00fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "import yaml\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(path_to_project)\n",
    "\n",
    "from sys import argv\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import (Callable, List, Optional, Sequence, Tuple, Union)\n",
    "from simple_runet import RUNet\n",
    "from simple_runet import DatasetCase2 as Dataset\n",
    "from simple_runet import TrainerCase2 as Trainer\n",
    "from simple_runet import get_multifield_loss, MULTIFIELD_LOSS_REGISTRY\n",
    "from simple_runet import plot0\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868dad2-304f-4048-b026-05a4646bac9b",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4377e3-f7fc-4308-9be6-244f0e5e6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "train_config:\n",
      " {'learning_rate': 0.0005, 'num_epochs': 100, 'weight_decay': 0.0, 'batch_size': 4, 'verbose': 1, 'gradient_clip': True, 'gradient_clip_val': 40, 'step_size': 1000, 'gamma': 0.9}\n",
      "=============================================\n",
      "model_config:\n",
      " {'filters': 16, 'units': [1, 1, 2], 'kernel_size': [5, 5, 1], 'padding': [2, 2, 0], 'with_control': True, 'with_states': True, 'norm_type': 'group', 'num_groups': 4, 'strides': [[2, 2, 1], [2, 2, 1]]}\n",
      "=============================================\n",
      "dataset_config:\n",
      " {'pred_length': 8, 'year': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_config, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "train_config = config[\"train_config\"]\n",
    "model_config = config[\"model_config\"]\n",
    "dataset_config = config[\"dataset_config\"]\n",
    "print(\"=============================================\\n\\\n",
    "train_config:\\n\", train_config)\n",
    "print(\"=============================================\\n\\\n",
    "model_config:\\n\", model_config)\n",
    "print(\"=============================================\\n\\\n",
    "dataset_config:\\n\", dataset_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe2e51-91a2-4a9a-80c4-a4edf7fa545b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b790290a-658c-467a-8828-5e76386294f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.96it/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.19it/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 16, 128, 512, 1]) torch.Size([500, 16, 128, 512, 1]) torch.Size([500, 1, 128, 512, 1])\n",
      "torch.Size([50, 16, 128, 512, 1]) torch.Size([50, 16, 128, 512, 1]) torch.Size([50, 1, 128, 512, 1])\n",
      "torch.Size([50, 16, 128, 512, 1]) torch.Size([50, 16, 128, 512, 1]) torch.Size([50, 1, 128, 512, 1])\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "batch_size = config['train_config']['batch_size'] # 4\n",
    "pred_length = config['dataset_config']['pred_length'] # 8\n",
    "year = config['dataset_config']['year'] # [0~15]\n",
    "timestep = [_ * 12 for _ in year]\n",
    "training_index = list(range(500))\n",
    "validate_index = list(range(500, 550))\n",
    "testing_index  = list(range(550, 600))\n",
    "\n",
    "training_set = Dataset(training_index, path_to_data, timestep, pred_length)\n",
    "train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validate_set = Dataset(validate_index, path_to_data, timestep, pred_length)\n",
    "valid_loader = DataLoader(validate_set, batch_size=1, shuffle=False)\n",
    "\n",
    "testing_set = Dataset(testing_index, path_to_data, timestep, pred_length)\n",
    "test_loader = DataLoader(testing_set, batch_size=1, shuffle=False)\n",
    "\n",
    "print(training_set.S.shape, training_set.P.shape, training_set.M.shape)\n",
    "print(validate_set.S.shape, validate_set.P.shape, validate_set.M.shape)\n",
    "print(testing_set.S.shape, testing_set.P.shape, testing_set.M.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5adc5-04c2-485f-88fc-d169d862bbba",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691a718a-8743-43e3-b86b-571fa7a40274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total trainable parameters: 3.002194 M\n"
     ]
    }
   ],
   "source": [
    "#  Build Model\n",
    "model = RUNet(**model_config).to(device)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of total trainable parameters: {trainable_params/1e6} M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348d2bb-ce25-472c-b322-d950d18a7322",
   "metadata": {},
   "source": [
    "# Build Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a660600-72fe-4c35-86cd-bce1be75c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config['regularizer_weight'] = 0.001\n",
    "pixel_loss = get_multifield_loss('pixel', loss_type='rel_mse', mode='both', reduce_dims=[1, 2, 3, 4])\n",
    "regularizer = get_multifield_loss('gradient', filter_type='sobel', loss_type='rel_l1', mode='both', reduce_dims=[1, 2, 3, 4])\n",
    "trainer = Trainer(model=model, \n",
    "                  train_config=train_config, \n",
    "                  pixel_loss=pixel_loss, \n",
    "                  # regularizer=regularizer,\n",
    "                  device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa1470-1fed-4be7-8f25-2c9867c7fba0",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59af4e-d939-43c1-b04c-0420a0a606ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch1/zhenq/2.SpatioTemporalSurrogate/checkpoint_case2D/runet_base_RMSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 251/1000 [02:52<08:32,  1.46it/s, loss=0.00918, loss_pixel=0.00918, loss_auxillary=0]"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "if not os.path.exists(path_to_model):\n",
    "    os.makedirs(path_to_model)\n",
    "print(path_to_model)\n",
    "\n",
    "loss_tracker_dict = trainer.train(train_loader, valid_loader, path_to_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9d0d0-c61b-4d6d-9fa5-c396617c0ddd",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6066100-c06d-4a2f-b940-5a7da03e7333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 400/400 [02:15<00:00,  2.95it/s, loss=0.0007, loss_pixel=0.0007, loss_auxillary=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('preds', torch.Size([400, 8, 2, 128, 512, 1])), ('outputs', torch.Size([400, 8, 2, 128, 512, 1])), ('states', torch.Size([400, 2, 128, 512, 1])), ('static', torch.Size([400, 1, 128, 512, 1]))]\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.test(test_loader)\n",
    "test_losses = test_results['losses']\n",
    "test_tensors = test_results['tensors']\n",
    "print([(k, v.shape) for k, v in test_tensors.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7835eabd-8b2e-41b7-809e-f13f47c5588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 8, 2, 128, 512, 1]) torch.Size([400, 8, 2, 128, 512, 1])\n",
      "torch.Size([400, 8, 128, 512, 1]) torch.Size([400, 8, 128, 512, 1])\n",
      "torch.Size([400, 8, 128, 512, 1]) torch.Size([400, 8, 128, 512, 1])\n"
     ]
    }
   ],
   "source": [
    "trues, preds = test_tensors['outputs'], test_tensors['preds']\n",
    "print(trues.shape, preds.shape)\n",
    "s_trues, s_preds = trues[:,:,1,...], preds[:,:,1,...]\n",
    "print(s_trues.shape, s_preds.shape)\n",
    "p_trues, p_preds = trues[:,:,0,...], preds[:,:,0,...]\n",
    "print(p_trues.shape, p_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efbd41-3e56-4303-9d34-45fd4d1b39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(20, 2)\n",
    "index, layer = 0, 0\n",
    "plot0(p_trues, p_preds, index, layer, figsize=figsize, error_cmap='seismic', error_vmin=-0.1, error_vmax=0.1)\n",
    "plot0(s_trues, s_preds, index, layer, figsize=figsize, error_cmap='seismic', error_vmin=-0.1, error_vmax=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_timm",
   "language": "python",
   "name": "torch_timm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
