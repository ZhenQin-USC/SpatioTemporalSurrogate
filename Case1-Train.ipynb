{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c0d26e-a07c-4b57-b211-91d6054fa994",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e11e8b-a5e5-4ddc-afbf-553b0f0c40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directories\n",
    "path_to_data = '/project2/jafarpou_227/Storage_Folder/Zhen/Data/CO2_Dataset/grid60_gaussian' # path to your data\n",
    "path_to_project = '/scratch1/zhenq/2.SpatioTemporalSurrogate' # path to the parent directory of your codebase 'simple_runet'\n",
    "path_to_model = '/scratch1/zhenq/2.SpatioTemporalSurrogate/checkpoint/runet_a_MSE_gradient' # path to checkpoint\n",
    "path_to_config = 'config/beginer_runet_a.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe9bb3b-463e-48be-86df-a61e2c53ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(path_to_project)\n",
    "\n",
    "from sys import argv\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import (Callable, List, Optional, Sequence, Tuple, Union)\n",
    "from simple_runet import RUNet #, RUNetParallel\n",
    "from simple_runet import memory_usage_psutil\n",
    "from simple_runet import DatasetCase1 as Dataset\n",
    "from simple_runet import Trainer_RUNET as Trainer\n",
    "from simple_runet import get_multifield_loss, MULTIFIELD_LOSS_REGISTRY\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf74f0f-df5b-46c0-89bb-9d8db654104c",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f11411-2233-4d10-bd80-038c244afbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "train_config:\n",
      " {'learning_rate': 0.001, 'num_epochs': 200, 'weight_decay': 0.0, 'batch_size': 2, 'verbose': 1, 'gradient_clip': False, 'gradient_clip_val': None, 'step_size': 400, 'gamma': 0.975}\n",
      "=============================================\n",
      "model_config:\n",
      " {'filters': 16, 'units': [1, 1, 2], 'norm_type': 'group', 'num_groups': 4, 'strides': [2, 2], 'with_control': False}\n",
      "=============================================\n",
      "dataset_config:\n",
      " {'num_years': 6, 'interval': 4, 'trainingset_folders': ['twowell_tworange_g20_z2', 'twowell_tworange_g60_z2', 'twowell_tworange_g100_z2', 'twowell_tworange_g20_z5', 'twowell_tworange_g60_z5', 'twowell_tworange_g100_z5'], 'validateset_folders': ['twowell_tworange_g20_z5']}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(path_to_config, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "train_config = config[\"train_config\"]\n",
    "model_config = config[\"model_config\"]\n",
    "dataset_config = config[\"dataset_config\"]\n",
    "print(\"=============================================\\n\\\n",
    "train_config:\\n\", train_config)\n",
    "print(\"=============================================\\n\\\n",
    "model_config:\\n\", model_config)\n",
    "print(\"=============================================\\n\\\n",
    "dataset_config:\\n\", dataset_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599851f-635f-4a25-b1a5-432c40d75347",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24dbc727-c302-4315-bd83-801d4112ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([499, 7, 64, 64, 20]) torch.Size([499, 7, 64, 64, 20]) torch.Size([499, 1, 64, 64, 20])\n",
      "torch.Size([50, 7, 64, 64, 20]) torch.Size([50, 7, 64, 64, 20]) torch.Size([50, 1, 64, 64, 20])\n",
      "torch.Size([50, 7, 64, 64, 20]) torch.Size([50, 7, 64, 64, 20]) torch.Size([50, 1, 64, 64, 20])\n"
     ]
    }
   ],
   "source": [
    "trainingset_folders = dataset_config['trainingset_folders']\n",
    "validateset_folders = dataset_config['validateset_folders']\n",
    "testingset_folders = validateset_folders\n",
    "try:\n",
    "    for folder in validateset_folders: \n",
    "        trainingset_folders.remove(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dataset_kwargs = {\n",
    "    'root_to_data': path_to_data, \n",
    "    'num_years': dataset_config['num_years'], \n",
    "    'interval': dataset_config['interval']\n",
    "}\n",
    "\n",
    "training_set = Dataset(folders=trainingset_folders, **dataset_kwargs)\n",
    "train_loader = DataLoader(training_set, batch_size=train_config['batch_size'], shuffle=True)\n",
    "print(training_set.s.shape, training_set.p.shape, training_set.m.shape)\n",
    "\n",
    "validate_set = Dataset(folders=validateset_folders, split_index=range(50), **dataset_kwargs)\n",
    "valid_loader = DataLoader(validate_set, batch_size=1, shuffle=False)\n",
    "print(validate_set.s.shape, validate_set.p.shape, validate_set.m.shape)\n",
    "\n",
    "test_set = Dataset(folders=testingset_folders, split_index=range(50,100), **dataset_kwargs)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "print(test_set.s.shape, test_set.p.shape, test_set.m.shape)\n",
    "\n",
    "data_loaders = (train_loader, valid_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d1777-6e68-418e-a6c4-889ee8a1282c",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f506a57d-1820-4f7b-a079-f7846916a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total trainable parameters: 3.034674 M\n"
     ]
    }
   ],
   "source": [
    "#  Build Model\n",
    "model = RUNet(**model_config).to(device)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of total trainable parameters: {trainable_params/1e6} M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637eeff-8b8f-45b0-845e-6a2331c94fd5",
   "metadata": {},
   "source": [
    "# Build Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2b6fc3-566a-405b-85a7-1510809af9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config['regularizer_weight'] = 0.001\n",
    "regularizer = get_multifield_loss('gradient', filter_type='sobel', loss_type='rel_l1', mode='both', reduce_dims=[1, 2, 3, 4])\n",
    "trainer = Trainer(model=model, train_config=train_config, pixel_loss=nn.MSELoss(), \n",
    "                  regularizer=regularizer, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c19ae-2308-46e2-938b-883ad135bdf1",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbd7d5-20c8-4f11-8a06-a066e4412023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 250/250 [00:47<00:00,  5.21it/s, loss=0.00681, loss_pixel=0.00561, loss_auxillary=1.19]\n",
      "Validing: 100%|██████████| 50/50 [00:01<00:00, 35.80it/s, loss=0.00212, loss_pixel=0.00143, loss_auxillary=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Train - loss: 0.0068 | loss_pixel: 0.0056 | loss_auxillary: 1.1937 | Valid - loss: 0.0021 | loss_pixel: 0.0014 | loss_auxillary: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 250/250 [00:46<00:00,  5.35it/s, loss=0.00258, loss_pixel=0.00191, loss_auxillary=0.668]\n",
      "Validing: 100%|██████████| 50/50 [00:01<00:00, 35.92it/s, loss=0.00222, loss_pixel=0.00166, loss_auxillary=0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: Train - loss: 0.0026 | loss_pixel: 0.0019 | loss_auxillary: 0.6682 | Valid - loss: 0.0022 | loss_pixel: 0.0017 | loss_auxillary: 0.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 250/250 [00:46<00:00,  5.38it/s, loss=0.00211, loss_pixel=0.00153, loss_auxillary=0.581]\n",
      "Validing: 100%|██████████| 50/50 [00:01<00:00, 31.30it/s, loss=0.00153, loss_pixel=0.001, loss_auxillary=0.524]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: Train - loss: 0.0021 | loss_pixel: 0.0015 | loss_auxillary: 0.5805 | Valid - loss: 0.0015 | loss_pixel: 0.0010 | loss_auxillary: 0.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 250/250 [00:46<00:00,  5.37it/s, loss=0.002, loss_pixel=0.00144, loss_auxillary=0.561]  \n",
      "Validing: 100%|██████████| 50/50 [00:01<00:00, 37.06it/s, loss=0.00154, loss_pixel=0.00102, loss_auxillary=0.524] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004: Train - loss: 0.0020 | loss_pixel: 0.0014 | loss_auxillary: 0.5607 | Valid - loss: 0.0015 | loss_pixel: 0.0010 | loss_auxillary: 0.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 125/250 [00:23<00:22,  5.48it/s, loss=0.00184, loss_pixel=0.00129, loss_auxillary=0.543]"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "if not os.path.exists(path_to_model):\n",
    "    os.makedirs(path_to_model)\n",
    "\n",
    "train_loss, valid_loss = trainer.train(train_loader, valid_loader, path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c18c91-fb9a-402d-8803-a3bab5451abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e83fe9-a312-4205-b509-536897b3c003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_timm",
   "language": "python",
   "name": "torch_timm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
